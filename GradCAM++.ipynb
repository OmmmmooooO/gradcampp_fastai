{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from utils import visualize_cam, Normalize\n",
    "from gradcam import GradCAM, GradCAMpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './'\n",
    "img_name = 'Abyssinian_72.jpg'\n",
    "img_path = os.path.join(img_dir, img_name)\n",
    "\n",
    "pil_img = PIL.Image.open(img_path)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "torch_img = torch.from_numpy(np.asarray(pil_img)).permute(2, 0, 1).unsqueeze(0).float().div(255).cuda()\n",
    "torch_img = F.upsample(torch_img, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "normed_torch_img = normalizer(torch_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and create fastai custom head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import logging as log\n",
    "from typing import Optional # required for \"Optional[type]\"\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n",
    "    def __init__(self, full:bool=False):\n",
    "        super().__init__()\n",
    "        self.full = full\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1) if self.full else x.view(x.size(0), -1)\n",
    "\n",
    "class AdaptiveConcatPool2d(torch.nn.Module):\n",
    "    \"Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d`.\" # from pytorch\n",
    "    def __init__(self, sz:Optional[int]=None): \n",
    "        \"Output will be 2*sz or 2 if sz is None\"\n",
    "        super().__init__()\n",
    "        self.output_size = sz or 1\n",
    "        self.ap = torch.nn.AdaptiveAvgPool2d(self.output_size)\n",
    "        self.mp = torch.nn.AdaptiveMaxPool2d(self.output_size)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "def fastaihead(nf, nc):\n",
    "    return \\\n",
    "    torch.nn.Sequential(        # the dropout is needed otherwise you cannot load the weights\n",
    "            AdaptiveConcatPool2d(),\n",
    "            Flatten(),\n",
    "            torch.nn.BatchNorm1d(nf),\n",
    "            torch.nn.Dropout(p=0.25, inplace=False),\n",
    "            torch.nn.Linear(nf, 512, bias=True),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.Dropout(p=0.5, inplace=False),\n",
    "            torch.nn.Linear(512, nc, bias=True),\n",
    "            torch.nn.BatchNorm1d(nc),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=models.resnet34() \n",
    "base_module=list(base_model.children())\n",
    "base_module.pop(-1) \n",
    "base_module.pop(-1)\n",
    "\n",
    "temp=torch.nn.Sequential(torch.nn.Sequential(*base_module))\n",
    "head_module=list(temp.children())\n",
    "head_module.append(fastaihead(1024,2))\n",
    "\n",
    "fastai_resnet34_arch=torch.nn.Sequential(*head_module)\n",
    "\n",
    "#for k in fastai_resnet34_arch.state_dict(): print(\"Module Layer\", k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weight into PyTorch for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = torch.load('./2_class.pth', map_location=torch.device('cpu'))\n",
    "#for k in loc['model']: print(\"layer\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fastai_resnet34_arch.load_state_dict(loc['model'])\n",
    "fastai_resnet34_arch.eval()\n",
    "fastai_resnet34_arch.cuda()\n",
    "\n",
    "#target_layer = fastai_resnet34_arch._modules['0']._modules['7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM & GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_dict = dict()\n",
    "fastai_resnet34_dict = dict(type='fastai_resnet34_arch', arch=fastai_resnet34_arch, layer_name='0', input_size=(500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_resnet34_gradcam = GradCAM(fastai_resnet34_dict, True)\n",
    "fastai_resnet34_gradcampp = GradCAMpp(fastai_resnet34_dict, True)\n",
    "\n",
    "cam_dict['fastai_resnet34'] = [fastai_resnet34_gradcam, fastai_resnet34_gradcampp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for gradcam, gradcam_pp in cam_dict.values():\n",
    "    mask, _ = gradcam(normed_torch_img)\n",
    "    heatmap, result = visualize_cam(mask, torch_img)\n",
    "\n",
    "    mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "    heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "\n",
    "    images.append(torch.stack([torch_img.squeeze().cpu(), heatmap, heatmap_pp, result, result_pp], 0))\n",
    "    \n",
    "images = make_grid(torch.cat(images, 0), nrow=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and show results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_name = img_name\n",
    "output_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "save_image(images, output_path)\n",
    "PIL.Image.open(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
